# ğŸ¤– MACHINE LEARNING PIPELINE - Há»† THá»NG PHÃ‚N LOáº I SPAM EMAIL

## ğŸ“‹ Tá»”NG QUAN Há»† THá»NG

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng má»™t há»‡ thá»‘ng hoÃ n chá»‰nh Ä‘á»ƒ phÃ¢n loáº¡i email spam/ham sá»­ dá»¥ng thuáº­t toÃ¡n **Naive Bayes** vá»›i **TF-IDF** vÃ  tÃ­ch há»£p **Gmail API** Ä‘á»ƒ quáº£n lÃ½ email thá»i gian thá»±c.

---

## ğŸ”„ MACHINE LEARNING PIPELINE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          ML PIPELINE WORKFLOW                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. THU THáº¬P Dá»® LIá»†U â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚  â€¢ Gmail API: Äá»“ng bá»™ email tá»« tÃ i khoáº£n Gmail
         â”‚  â€¢ Manual Input: NgÆ°á»i dÃ¹ng thÃªm email qua giao diá»‡n
         â”‚  â€¢ Dataset CSV: spam_data.csv (10,000+ máº«u)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. LÆ¯U TRá»® Dá»® LIá»†U  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚  File: spam_data.csv
         â”‚  Format: [label, text]
         â”‚  Labels: "spam" hoáº·c "ham"
         â”‚  
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. TIá»€N Xá»¬ LÃ VÄ‚N Báº¢Nâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚  a) Loáº¡i bá» tháº» HTML
         â”‚  b) Chuáº©n hÃ³a URL â†’ "URL"
         â”‚  c) Chuáº©n hÃ³a Email â†’ "EMAIL"
         â”‚  d) Chuáº©n hÃ³a SÄT â†’ "PHONE"
         â”‚  e) Normalize Unicode (NFC)
         â”‚  f) Chuyá»ƒn chá»¯ thÆ°á»ng
         â”‚  g) TÃ¡ch tá»« (NLTK tokenization)
         â”‚  h) Loáº¡i bá» stopwords (tá»« file stopwords.txt)
         â”‚  i) Loáº¡i bá» tá»« ngáº¯n (<3 kÃ½ tá»±)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. CHIA Táº¬P Dá»® LIá»†U  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚  â€¢ Train Set:      60% (huáº¥n luyá»‡n model)
         â”‚  â€¢ Validation Set: 20% (tá»‘i Æ°u tham sá»‘)
         â”‚  â€¢ Test Set:       20% (Ä‘Ã¡nh giÃ¡ cuá»‘i cÃ¹ng)
         â”‚  
         â”‚  Sá»­ dá»¥ng: train_test_split vá»›i stratify
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. VECTOR HÃ“A Äáº¶C TRÆ¯NGâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚  Thuáº­t toÃ¡n: TF-IDF (Term Frequency-Inverse Document Frequency)
         â”‚  
         â”‚  Tham sá»‘ (tá»‘i Æ°u qua GridSearchCV):
         â”‚  â€¢ max_features: [3000, 5000, 10000]
         â”‚  â€¢ ngram_range: [(1,1), (1,2)]
         â”‚  â€¢ min_df: [2, 3]
         â”‚  
         â”‚  Output: Ma tráº­n sparse TF-IDF
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. HUáº¤N LUYá»†N MODEL   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚  Thuáº­t toÃ¡n: Multinomial Naive Bayes
         â”‚  
         â”‚  Tá»‘i Æ°u tham sá»‘ vá»›i GridSearchCV:
         â”‚  â€¢ alpha (Laplace smoothing): [0.01, 0.1, 0.5, 1.0]
         â”‚  â€¢ Cross-validation: 5-fold CV
         â”‚  â€¢ Scoring metric: F1-weighted
         â”‚  
         â”‚  CÃ´ng thá»©c Naive Bayes:
         â”‚  P(spam|email) âˆ P(email|spam) Ã— P(spam)
         â”‚  
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. ÄÃNH GIÃ MODEL    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚  Metrics Ä‘Æ°á»£c tÃ­nh trÃªn 3 táº­p:
         â”‚  
         â”‚  ğŸ“Š TRAIN SET METRICS:
         â”‚     â†’ Kiá»ƒm tra kháº£ nÄƒng há»c cá»§a model
         â”‚  
         â”‚  ğŸ“Š VALIDATION SET METRICS:
         â”‚     â†’ PhÃ¡t hiá»‡n overfitting
         â”‚     â†’ So sÃ¡nh Train vs Val accuracy
         â”‚  
         â”‚  ğŸ“Š TEST SET METRICS (Final Evaluation):
         â”‚     â€¢ Accuracy:  % dá»± Ä‘oÃ¡n Ä‘Ãºng
         â”‚     â€¢ Precision: % spam dá»± Ä‘oÃ¡n Ä‘Ãºng trong tá»•ng sá»‘ dá»± Ä‘oÃ¡n spam
         â”‚     â€¢ Recall:    % spam Ä‘Æ°á»£c phÃ¡t hiá»‡n trong tá»•ng sá»‘ spam thá»±c táº¿
         â”‚     â€¢ F1-Score:  Trung bÃ¬nh Ä‘iá»u hÃ²a cá»§a Precision & Recall
         â”‚     â€¢ Confusion Matrix: Ma tráº­n nháº§m láº«n
         â”‚  
         â”‚  ğŸ” OVERFITTING CHECK:
         â”‚     IF (Train_Accuracy - Val_Accuracy) > 10%
         â”‚        â†’ âš ï¸  Cáº¢NH BÃO: Model Ä‘ang overfitting!
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. LÆ¯U MODEL         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚  Files Ä‘Æ°á»£c lÆ°u:
         â”‚  â€¢ spam_pipeline.pkl       â†’ Pipeline hoÃ n chá»‰nh (TF-IDF + Model)
         â”‚  â€¢ training_metrics.json   â†’ Metrics chi tiáº¿t cá»§a quÃ¡ trÃ¬nh huáº¥n luyá»‡n
         â”‚  â€¢ model_performance.png   â†’ Biá»ƒu Ä‘á»“ hiá»‡u suáº¥t
         â”‚  â€¢ confusion_matrix.png    â†’ Ma tráº­n nháº§m láº«n
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 9. TRIá»‚N KHAI & Sá»¬ Dá»¤NGâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚  â€¢ Load pipeline tá»« spam_pipeline.pkl
         â”‚  â€¢ Nháº­n email tá»« Gmail API
         â”‚  â€¢ Tiá»n xá»­ lÃ½ email
         â”‚  â€¢ Dá»± Ä‘oÃ¡n spam/ham vá»›i confidence score
         â”‚  â€¢ TrÃ­ch xuáº¥t top keywords áº£nh hÆ°á»Ÿng
         â”‚  â€¢ Hiá»ƒn thá»‹ káº¿t quáº£ trÃªn giao diá»‡n
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 10. Há»ŒC LIÃŠN Tá»¤C     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚  â€¢ NgÆ°á»i dÃ¹ng Ä‘Ã¡nh dáº¥u email spam/ham
         â”‚  â€¢ ThÃªm vÃ o dataset (spam_data.csv)
         â”‚  â€¢ Retrain model khi cÃ³ dá»¯ liá»‡u má»›i
         â”‚  â€¢ Cáº­p nháº­t pipeline
         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º (Quay láº¡i bÆ°á»›c 3)
```

---

## ğŸ§® CHI TIáº¾T CÃC THUáº¬T TOÃN

### 1. **TF-IDF Vectorization**

**TF-IDF (Term Frequency - Inverse Document Frequency)** lÃ  phÆ°Æ¡ng phÃ¡p vector hÃ³a vÄƒn báº£n, chuyá»ƒn Ä‘á»•i text thÃ nh sá»‘.

#### CÃ´ng thá»©c:

```
TF-IDF(t, d) = TF(t, d) Ã— IDF(t)

Trong Ä‘Ã³:
â€¢ TF(t, d)  = Sá»‘ láº§n tá»« t xuáº¥t hiá»‡n trong document d / Tá»•ng sá»‘ tá»« trong d
â€¢ IDF(t)    = log(Tá»•ng sá»‘ documents / Sá»‘ documents chá»©a tá»« t)
```

#### Ã nghÄ©a:
- **TF**: Tá»« xuáº¥t hiá»‡n nhiá»u â†’ quan trá»ng trong document Ä‘Ã³
- **IDF**: Tá»« xuáº¥t hiá»‡n Ã­t trong corpus â†’ cÃ³ tÃ­nh phÃ¢n biá»‡t cao
- **TF-IDF cao**: Tá»« quan trá»ng vÃ  Ä‘áº·c trÆ°ng cho document

#### VÃ­ dá»¥:

```
Email spam: "KHUYáº¾N MÃƒI Ä‘áº·c biá»‡t, KHUYáº¾N MÃƒI háº¥p dáº«n"
Email ham:  "ChÃ o báº¡n, háº¹n gáº·p láº¡i"

â†’ "KHUYáº¾N MÃƒI" cÃ³ TF cao trong email spam
â†’ "KHUYáº¾N MÃƒI" xuáº¥t hiá»‡n Ã­t trong toÃ n bá»™ emails â†’ IDF cao
â†’ TF-IDF("KHUYáº¾N MÃƒI") ráº¥t cao â†’ Äáº·c trÆ°ng cá»§a spam
```

### 2. **Multinomial Naive Bayes**

**Naive Bayes** lÃ  thuáº­t toÃ¡n phÃ¢n loáº¡i xÃ¡c suáº¥t dá»±a trÃªn **Äá»‹nh lÃ½ Bayes**.

#### CÃ´ng thá»©c cÆ¡ báº£n:

```
P(spam | email) = P(email | spam) Ã— P(spam) / P(email)

Trong Ä‘Ã³:
â€¢ P(spam | email): XÃ¡c suáº¥t email lÃ  spam khi biáº¿t ná»™i dung
â€¢ P(email | spam): XÃ¡c suáº¥t email cÃ³ ná»™i dung nÃ y khi lÃ  spam
â€¢ P(spam):         XÃ¡c suáº¥t tiÃªn nghiá»‡m (prior probability)
â€¢ P(email):        XÃ¡c suáº¥t email (constant, cÃ³ thá»ƒ bá» qua)
```

#### Giáº£ Ä‘á»‹nh "Naive" (NgÃ¢y thÆ¡):

CÃ¡c tá»« trong email **Ä‘á»™c láº­p** vá»›i nhau:

```
P(email | spam) = P(wâ‚ | spam) Ã— P(wâ‚‚ | spam) Ã— ... Ã— P(wâ‚™ | spam)
```

#### Multinomial Naive Bayes cho text:

```
log P(spam | email) = log P(spam) + Î£ count(wáµ¢) Ã— log P(wáµ¢ | spam)

Trong Ä‘Ã³:
â€¢ count(wáµ¢): Sá»‘ láº§n tá»« wáµ¢ xuáº¥t hiá»‡n trong email
â€¢ P(wáµ¢ | spam) = (sá»‘ láº§n wáµ¢ xuáº¥t hiá»‡n trong spam + Î±) / 
                 (tá»•ng sá»‘ tá»« trong spam + Î± Ã— V)
â€¢ Î±: Laplace smoothing parameter (trÃ¡nh xÃ¡c suáº¥t = 0)
â€¢ V: KÃ­ch thÆ°á»›c vocabulary
```

#### Laplace Smoothing (Î±):

- **Váº¥n Ä‘á»**: Náº¿u tá»« má»›i chÆ°a tá»«ng xuáº¥t hiá»‡n trong training â†’ P = 0 â†’ Lá»—i!
- **Giáº£i phÃ¡p**: ThÃªm Î± vÃ o tá»­ sá»‘ vÃ  Î±Ã—V vÃ o máº«u sá»‘
- **Tham sá»‘ tá»‘i Æ°u** (qua GridSearchCV): Î± = [0.01, 0.1, 0.5, 1.0]

#### VÃ­ dá»¥ phÃ¢n loáº¡i:

```
Email má»›i: "KHUYáº¾N MÃƒI Ä‘áº·c biá»‡t"

BÆ°á»›c 1: TÃ­nh prior
P(spam) = 0.6 (60% email trong training lÃ  spam)
P(ham)  = 0.4

BÆ°á»›c 2: TÃ­nh likelihood
P("KHUYáº¾N" | spam) = 0.15
P("MÃƒI" | spam)    = 0.12
P("Ä‘áº·c" | spam)    = 0.08
P("biá»‡t" | spam)   = 0.07

P("KHUYáº¾N" | ham)  = 0.01
P("MÃƒI" | ham)     = 0.01
P("Ä‘áº·c" | ham)     = 0.05
P("biá»‡t" | ham)    = 0.04

BÆ°á»›c 3: TÃ­nh posterior (log scale)
log P(spam | email) = log(0.6) + log(0.15) + log(0.12) + log(0.08) + log(0.07)
                    = -0.51 + (-1.90) + (-2.12) + (-2.53) + (-2.66)
                    = -9.72

log P(ham | email)  = log(0.4) + log(0.01) + log(0.01) + log(0.05) + log(0.04)
                    = -0.92 + (-4.61) + (-4.61) + (-3.00) + (-3.22)
                    = -16.36

BÆ°á»›c 4: So sÃ¡nh
-9.72 > -16.36 â†’ Email lÃ  SPAM
Confidence = exp(-9.72) / [exp(-9.72) + exp(-16.36)] â‰ˆ 99.9%
```

---

## ğŸ“Š QUY TRÃŒNH ÄÃNH GIÃ MODEL

### Metrics ÄÃ¡nh GiÃ¡

#### 1. **Accuracy (Äá»™ chÃ­nh xÃ¡c)**

```
Accuracy = (TP + TN) / (TP + TN + FP + FN)

TP: True Positive  (Dá»± Ä‘oÃ¡n spam, thá»±c táº¿ spam)
TN: True Negative  (Dá»± Ä‘oÃ¡n ham, thá»±c táº¿ ham)
FP: False Positive (Dá»± Ä‘oÃ¡n spam, thá»±c táº¿ ham) â† Type I Error
FN: False Negative (Dá»± Ä‘oÃ¡n ham, thá»±c táº¿ spam)  â† Type II Error
```

**Ã nghÄ©a**: % email Ä‘Æ°á»£c phÃ¢n loáº¡i Ä‘Ãºng

#### 2. **Precision (Äá»™ chÃ­nh xÃ¡c cá»§a dá»± Ä‘oÃ¡n spam)**

```
Precision = TP / (TP + FP)
```

**Ã nghÄ©a**: Trong sá»‘ email dá»± Ä‘oÃ¡n lÃ  spam, bao nhiÃªu % thá»±c sá»± lÃ  spam?
- **Precision cao** â†’ Ãt email bÃ¬nh thÆ°á»ng bá»‹ nháº§m lÃ  spam (FP tháº¥p)

#### 3. **Recall (Äá»™ nháº¡y, Sensitivity)**

```
Recall = TP / (TP + FN)
```

**Ã nghÄ©a**: Trong sá»‘ email spam thá»±c táº¿, bao nhiÃªu % Ä‘Æ°á»£c phÃ¡t hiá»‡n?
- **Recall cao** â†’ PhÃ¡t hiá»‡n Ä‘Æ°á»£c nhiá»u spam (FN tháº¥p)

#### 4. **F1-Score**

```
F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
```

**Ã nghÄ©a**: Trung bÃ¬nh Ä‘iá»u hÃ²a cá»§a Precision vÃ  Recall
- **F1 cao** â†’ CÃ¢n báº±ng giá»¯a Precision vÃ  Recall

### Confusion Matrix

```
                  Predicted
                Spam    Ham
Actual  Spam  â”‚  TP  â”‚  FN  â”‚
        Ham   â”‚  FP  â”‚  TN  â”‚
```

### Kiá»ƒm tra Overfitting

```python
accuracy_diff = Train_Accuracy - Validation_Accuracy

if accuracy_diff > 0.1:
    print("âš ï¸ Cáº¢NH BÃO: Model Ä‘ang overfitting!")
    print("â†’ Model há»c thuá»™c training data, khÃ´ng tá»•ng quÃ¡t hÃ³a tá»‘t")
    print("â†’ Giáº£i phÃ¡p: TÄƒng alpha, giáº£m max_features, thu tháº­p thÃªm dá»¯ liá»‡u")
```

---

## ğŸ”§ THAM Sá» Tá»I ÃšU (GridSearchCV)

### KhÃ´ng gian tham sá»‘

```python
param_grid = {
    'vectorizer__max_features': [3000, 5000, 10000],
    'vectorizer__ngram_range': [(1, 1), (1, 2)],
    'vectorizer__min_df': [2, 3],
    'classifier__alpha': [0.01, 0.1, 0.5, 1.0]
}
```

### Giáº£i thÃ­ch tham sá»‘

| Tham sá»‘ | Ã nghÄ©a | GiÃ¡ trá»‹ | áº¢nh hÆ°á»Ÿng |
|---------|---------|---------|-----------|
| **max_features** | Sá»‘ lÆ°á»£ng tá»« tá»‘i Ä‘a | 3k, 5k, 10k | â†‘ â†’ Nhiá»u Ä‘áº·c trÆ°ng, cÃ³ thá»ƒ overfitting |
| **ngram_range** | Káº¿t há»£p tá»« | (1,1): unigram<br>(1,2): unigram + bigram | (1,2) â†’ Báº¯t cá»¥m tá»« "khuyáº¿n mÃ£i" |
| **min_df** | Tá»« xuáº¥t hiá»‡n tá»‘i thiá»ƒu | 2, 3 documents | â†‘ â†’ Loáº¡i bá» tá»« hiáº¿m, giáº£m noise |
| **alpha** | Laplace smoothing | 0.01 Ä‘áº¿n 1.0 | â†‘ â†’ Ãt overfitting, nhÆ°ng cÃ³ thá»ƒ kÃ©m chÃ­nh xÃ¡c |

### QuÃ¡ trÃ¬nh tÃ¬m kiáº¿m

```
Tá»•ng sá»‘ káº¿t há»£p: 3 Ã— 2 Ã— 2 Ã— 4 = 48 káº¿t há»£p
Cross-validation: 5-fold CV
Tá»•ng sá»‘ láº§n huáº¥n luyá»‡n: 48 Ã— 5 = 240 láº§n

â†’ GridSearchCV tá»± Ä‘á»™ng chá»n káº¿t há»£p tá»‘t nháº¥t dá»±a trÃªn F1-score
```

---

## ğŸ“‚ Cáº¤U TRÃšC Dá»® LIá»†U & FILE

### 1. Dataset (spam_data.csv)

```csv
label,text
ham,"Cho mÃ¬nh há»i, báº¡n cÃ³ presentation khÃ´ng?"
spam,"ğŸ’° CÆ  Há»˜I VIá»†C LÃ€M: Thu nháº­p 2000-1500k/thÃ¡ng"
spam,"ğŸ“ˆ KIáº¾M 5000K/NGÃ€Y tá»« Dogecoin!"
ham,"Wishing you a beautiful day."
```

**Äáº·c Ä‘iá»ƒm**:
- HÆ¡n 10,000 máº«u email tiáº¿ng Viá»‡t vÃ  tiáº¿ng Anh
- CÃ¢n báº±ng tÆ°Æ¡ng Ä‘á»‘i giá»¯a spam/ham
- ÄÆ°á»£c cáº­p nháº­t liÃªn tá»¥c tá»« ngÆ°á»i dÃ¹ng

### 2. Stopwords (stopwords.txt)

```text
vÃ 
cá»§a
cÃ³
trong
Ä‘Æ°á»£c
...
```

**Má»¥c Ä‘Ã­ch**: Loáº¡i bá» cÃ¡c tá»« phá»• biáº¿n khÃ´ng mang Ã½ nghÄ©a phÃ¢n loáº¡i

### 3. Model Files

```
spam_pipeline.pkl          â†’ Pipeline hoÃ n chá»‰nh (TF-IDF + Naive Bayes)
training_metrics.json      â†’ Chi tiáº¿t metrics cá»§a training
model_performance.png      â†’ Biá»ƒu Ä‘á»“ Accuracy, Precision, Recall, F1
confusion_matrix.png       â†’ Ma tráº­n nháº§m láº«n
```

### 4. Training Metrics (training_metrics.json)

```json
{
  "timestamp": "2025-10-22 14:30:00",
  "train": {
    "accuracy": 0.9845,
    "precision": 0.9821,
    "recall": 0.9867,
    "f1_score": 0.9844,
    "samples": 6000
  },
  "validation": {
    "accuracy": 0.9623,
    "precision": 0.9587,
    "recall": 0.9658,
    "f1_score": 0.9622,
    "samples": 2000
  },
  "test": {
    "accuracy": 0.9651,
    "precision": 0.9612,
    "recall": 0.9689,
    "f1_score": 0.9650,
    "samples": 2000
  },
  "best_params": {
    "vectorizer__max_features": 5000,
    "vectorizer__ngram_range": [1, 2],
    "vectorizer__min_df": 2,
    "classifier__alpha": 0.1
  },
  "overfitting_check": {
    "train_test_gap": 0.0194,
    "train_val_gap": 0.0222,
    "is_overfitting": false
  }
}
```

---

## ğŸ¯ TÃCH Há»¢P VÃ€O á»¨NG Dá»¤NG

### Luá»“ng sá»­ dá»¥ng Model trong Production

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER FLOW - Sá»¬ Dá»¤NG MODEL                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User Ä‘Äƒng nháº­p Gmail
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Láº¥y email tá»« Gmail â”‚ â† gmail_oauth.py â†’ Gmail API
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ [Email List]
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tiá»n xá»­ lÃ½ email   â”‚ â† preprocess_text() trong naive_bayes.py
â”‚  â€¢ Loáº¡i HTML       â”‚
â”‚  â€¢ Normalize       â”‚
â”‚  â€¢ Tokenize        â”‚
â”‚  â€¢ Remove stopwordsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ [Processed Text]
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Load Pipeline      â”‚ â† joblib.load('spam_pipeline.pkl')
â”‚  â€¢ TF-IDF          â”‚
â”‚  â€¢ Naive Bayes     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PhÃ¢n loáº¡i email    â”‚ â† classify_email()
â”‚  1. Vectorize      â”‚ â† vectorizer.transform()
â”‚  2. Predict        â”‚ â† model.predict()
â”‚  3. Get proba      â”‚ â† model.predict_proba()
â”‚  4. Extract        â”‚ â† PhÃ¢n tÃ­ch tá»« khÃ³a, email stats
â”‚     keywords       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ [Classification Result]
         â”‚ â€¢ classification: "spam" hoáº·c "ham"
         â”‚ â€¢ confidence: 95.67%
         â”‚ â€¢ top_keywords: [...]
         â”‚ â€¢ email_stats: {...}
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Hiá»ƒn thá»‹ káº¿t quáº£   â”‚ â† React Frontend
â”‚  â€¢ Badge spam/ham  â”‚
â”‚  â€¢ Confidence %    â”‚
â”‚  â€¢ Keywords        â”‚
â”‚  â€¢ Suggestion      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
User action:
  â€¢ ÄÃ¡nh dáº¥u spam    â†’ mark_spam() â†’ Add to dataset â†’ Retrain
  â€¢ Bá» Ä‘Ã¡nh dáº¥u spam â†’ mark_not_spam() â†’ Add to dataset â†’ Retrain
  â€¢ PhÃ¢n tÃ­ch thá»§ cÃ´ng â†’ analyze_text() â†’ Hiá»ƒn thá»‹ chi tiáº¿t
```

### API Endpoints sá»­ dá»¥ng Model

#### 1. `/emails` - Láº¥y vÃ  phÃ¢n loáº¡i email inbox

```python
@app.route('/emails')
def get_emails_route():
    # 1. Láº¥y email tá»« Gmail API
    service = get_gmail_service()
    result = get_emails(service, max_results=20)
    
    # 2. Trong get_emails(), má»—i email Ä‘Æ°á»£c phÃ¢n loáº¡i:
    for email in emails:
        MODEL, VECTORIZER = initialize_model()
        result = classify_email(MODEL, VECTORIZER, 
                               email['content'], 
                               email['subject'])
        email.update(result)  # ThÃªm classification, confidence, keywords
    
    return jsonify(result)
```

#### 2. `/spam_emails` - Láº¥y email spam

TÆ°Æ¡ng tá»± `/emails` nhÆ°ng filter theo label SPAM

#### 3. `/analyze_text` - PhÃ¢n tÃ­ch email thá»§ cÃ´ng

```python
@app.route('/analyze_text', methods=['POST'])
def analyze_text():
    data = request.json
    subject = data.get('subject', '')
    content = data.get('content', '')
    
    # Load model
    model, vectorizer = initialize_model()
    
    # PhÃ¢n loáº¡i
    result = classify_email(model, vectorizer, content, subject)
    
    return jsonify(result)
```

#### 4. `/add_to_dataset` - ThÃªm dá»¯ liá»‡u & Retrain

```python
@app.route('/add_to_dataset', methods=['POST'])
def add_to_dataset():
    # 1. ThÃªm email vÃ o spam_data.csv
    new_data = pd.DataFrame({
        'label': [label], 
        'text': [full_text]
    })
    df = pd.concat([df, new_data])
    df.to_csv(DATA_FILE)
    
    # 2. Huáº¥n luyá»‡n láº¡i model
    MODEL, VECTORIZER = train_model(DATA_FILE)
    
    return jsonify({'success': True})
```

#### 5. `/retrain` - Huáº¥n luyá»‡n láº¡i model

```python
@app.route('/retrain', methods=['POST'])
def retrain_model():
    global MODEL, VECTORIZER
    
    # XÃ³a pipeline cÅ©
    os.remove(PIPELINE_PATH)
    
    # Reset biáº¿n global
    MODEL, VECTORIZER = None, None
    
    # Huáº¥n luyá»‡n má»›i
    MODEL, VECTORIZER = train_model(DATA_FILE)
    
    return jsonify({'success': True})
```

---

## ğŸ“ˆ PHÃ‚N TÃCH Káº¾T QUáº¢

### Output cá»§a classify_email()

```python
{
    'classification': 'spam',
    'confidence': 95.67,
    'top_keywords': [
        {
            'word': 'khuyáº¿n',
            'weight': -2.145,
            'impact': 3.456,
            'explanation': 'Tá»« nÃ y thÆ°á»ng xuáº¥t hiá»‡n trong spam'
        },
        {
            'word': 'mÃ£i',
            'weight': -2.287,
            'impact': 3.234,
            'explanation': 'Tá»« nÃ y thÆ°á»ng xuáº¥t hiá»‡n trong spam'
        },
        // ... top 20 keywords
    ],
    'email_stats': {
        'total_length': 245,
        'word_count': 42,
        'uppercase_ratio': 0.15,
        'has_urls': True,
        'has_numbers': True,
        'special_char_count': 8
    }
}
```

### Giáº£i thÃ­ch tá»« khÃ³a (Keywords Explanation)

```python
# TÃ­nh impact score cho má»—i tá»«
impact = log_prob_spam - log_prob_ham

# Impact > 0: Tá»« Ä‘áº·c trÆ°ng cho spam
# Impact < 0: Tá»« Ä‘áº·c trÆ°ng cho ham
# |Impact| lá»›n: Tá»« cÃ³ sá»©c áº£nh hÆ°á»Ÿng máº¡nh Ä‘áº¿n káº¿t quáº£ phÃ¢n loáº¡i
```

---

## ğŸ”„ Há»ŒC LIÃŠN Tá»¤C (Continuous Learning)

### Quy trÃ¬nh cáº­p nháº­t model

```
User Ä‘Ã¡nh dáº¥u email
         â”‚
         â–¼
add_to_dataset_internal()
         â”‚
         â”œâ”€â†’ Kiá»ƒm tra trÃ¹ng láº·p trong spam_data.csv
         â”‚
         â”œâ”€â†’ Náº¿u má»›i: ThÃªm vÃ o CSV
         â”‚   Náº¿u trÃ¹ng nhÆ°ng khÃ¡c label: Cáº­p nháº­t label
         â”‚
         â–¼
train_model(spam_data.csv)
         â”‚
         â”œâ”€â†’ Äá»c dá»¯ liá»‡u má»›i
         â”œâ”€â†’ GridSearchCV tÃ¬m tham sá»‘ tá»‘i Æ°u
         â”œâ”€â†’ Huáº¥n luyá»‡n láº¡i pipeline
         â”œâ”€â†’ ÄÃ¡nh giÃ¡ metrics má»›i
         â”œâ”€â†’ LÆ°u spam_pipeline.pkl
         â”‚
         â–¼
Model Ä‘Æ°á»£c cáº­p nháº­t
         â”‚
         â””â”€â†’ DÃ¹ng cho cÃ¡c dá»± Ä‘oÃ¡n tiáº¿p theo
```

### Khi nÃ o nÃªn Retrain?

1. **Tá»± Ä‘á»™ng**: Khi thÃªm dá»¯ liá»‡u qua `add_to_dataset`
2. **Thá»§ cÃ´ng**: User click "Retrain Model" trÃªn giao diá»‡n
3. **Äá»‹nh ká»³**: Náº¿u cÃ³ nhiá»u dá»¯ liá»‡u má»›i tÃ­ch lÅ©y

---

## ğŸ¨ TRá»°C QUAN HÃ“A

### 1. Biá»ƒu Ä‘á»“ hiá»‡u suáº¥t (model_performance.png)

```
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  Model Performance Metrics           â”‚
120% â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚                                      â”‚
100% â”‚  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ              â”‚
 80% â”‚  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ              â”‚
 60% â”‚  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ              â”‚
 40% â”‚  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ              â”‚
 20% â”‚  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ              â”‚
  0% â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      Acc   Prec  Rec   F1
     96.5% 96.1% 96.9% 96.5%
```

### 2. Ma tráº­n nháº§m láº«n (confusion_matrix.png)

```
                Predicted
             Spam    Ham
Actual  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  Spam  â”‚  970  â”‚   30   â”‚  1000
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  Ham   â”‚   40  â”‚  960   â”‚  1000
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         1010    990

â†’ Precision (spam) = 970/1010 = 96.0%
â†’ Recall (spam)    = 970/1000 = 97.0%
```

---

## ğŸ’¡ BEST PRACTICES & TIPS

### 1. Tiá»n xá»­ lÃ½ vÄƒn báº£n

âœ… **LÃ m:**
- Normalize Unicode (NFC) cho tiáº¿ng Viá»‡t
- Loáº¡i bá» stopwords phÃ¹ há»£p vá»›i ngá»¯ cáº£nh
- Chuáº©n hÃ³a URL, Email, Phone â†’ Giáº£m chiá»u dá»¯ liá»‡u

âŒ **TrÃ¡nh:**
- Loáº¡i bá» quÃ¡ nhiá»u thÃ´ng tin (vÃ­ dá»¥: dáº¥u cÃ¢u cÃ³ thá»ƒ quan trá»ng)
- Stemming/Lemmatization khÃ´ng phÃ¹ há»£p vá»›i tiáº¿ng Viá»‡t

### 2. Chá»n thuáº­t toÃ¡n

âœ… **Naive Bayes phÃ¹ há»£p khi:**
- Dá»¯ liá»‡u text nhiá»u chiá»u
- Cáº§n tá»‘c Ä‘á»™ nhanh
- Dá»¯ liá»‡u training khÃ´ng quÃ¡ lá»›n (< 100k máº«u)

âŒ **CÃ¢n nháº¯c thuáº­t toÃ¡n khÃ¡c náº¿u:**
- Cáº§n Ä‘á»™ chÃ­nh xÃ¡c cá»±c cao â†’ SVM, Random Forest
- CÃ³ nhiá»u dá»¯ liá»‡u (> 100k) â†’ Deep Learning (LSTM, BERT)

### 3. ÄÃ¡nh giÃ¡ model

âœ… **Quan trá»ng:**
- Chia Train/Val/Test Ä‘Ãºng cÃ¡ch
- Kiá»ƒm tra overfitting (Train vs Val accuracy)
- Sá»­ dá»¥ng F1-score cho dá»¯ liá»‡u máº¥t cÃ¢n báº±ng

âŒ **Sai láº§m thÆ°á»ng gáº·p:**
- Chá»‰ nhÃ¬n Accuracy (cÃ³ thá»ƒ misleading náº¿u data imbalanced)
- KhÃ´ng kiá»ƒm tra Precision/Recall riÃªng biá»‡t
- Test trÃªn data Ä‘Ã£ tháº¥y trong training

### 4. Continuous Learning

âœ… **NÃªn:**
- Backup dataset trÆ°á»›c khi retrain
- LÆ°u láº¡i metrics má»—i láº§n retrain Ä‘á»ƒ theo dÃµi xu hÆ°á»›ng
- Validate user feedback trÆ°á»›c khi thÃªm vÃ o dataset

âŒ **TrÃ¡nh:**
- ThÃªm dá»¯ liá»‡u nhiá»…u (low quality) vÃ o dataset
- Retrain quÃ¡ thÆ°á»ng xuyÃªn mÃ  khÃ´ng Ä‘Ã¡nh giÃ¡ káº¿t quáº£

---

## ğŸ“š TÃ€I LIá»†U THAM KHáº¢O

### Thuáº­t toÃ¡n
- [Naive Bayes Classifier - Wikipedia](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)
- [TF-IDF - Wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)
- [Scikit-learn Documentation](https://scikit-learn.org/stable/)

### Metrics
- [Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall)
- [F1 Score](https://en.wikipedia.org/wiki/F-score)
- [Confusion Matrix](https://en.wikipedia.org/wiki/Confusion_matrix)

---

## ğŸ”® HÆ¯á»šNG PHÃT TRIá»‚N

### Cáº£i tiáº¿n Model

1. **Ensemble Methods**
   ```
   Káº¿t há»£p Naive Bayes + SVM + Random Forest
   â†’ Voting Classifier Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c
   ```

2. **Deep Learning**
   ```
   PhoBERT (BERT for Vietnamese) cho email tiáº¿ng Viá»‡t
   â†’ Báº¯t Ä‘Æ°á»£c ngá»¯ cáº£nh tá»‘t hÆ¡n
   ```

3. **Feature Engineering**
   ```
   â€¢ Email header analysis (sender reputation)
   â€¢ Link analysis (check spam domains)
   â€¢ Attachment detection
   â€¢ Email metadata (time, size)
   ```

### Cáº£i tiáº¿n Há»‡ thá»‘ng

1. **Auto-Retrain**
   ```python
   # Tá»± Ä‘á»™ng retrain khi cÃ³ N máº«u má»›i
   if new_samples_count >= 100:
       retrain_model()
   ```

2. **A/B Testing**
   ```
   So sÃ¡nh model cÅ© vs model má»›i
   â†’ Chá»n model tá»‘t hÆ¡n
   ```

3. **Model Versioning**
   ```
   spam_pipeline_v1.pkl
   spam_pipeline_v2.pkl
   â†’ Rollback náº¿u model má»›i kÃ©m hÆ¡n
   ```

---

## ğŸ“ Há»– TRá»¢

Náº¿u cÃ³ tháº¯c máº¯c vá» ML Pipeline, vui lÃ²ng tham kháº£o:
- **Code**: `naive_bayes.py`, `app.py`
- **Documentation**: `ARCHITECTURE.md`, `README.md`
- **Training Logs**: `training_metrics.json`

---

**ğŸ“… Cáº­p nháº­t láº§n cuá»‘i**: 22/10/2025  
**ğŸ·ï¸ PhiÃªn báº£n**: 1.0  
**ğŸ‘¨â€ğŸ’» TÃ¡c giáº£**: InfinityZero3000
